{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.layers import RandomContrast, RandomZoom, RandomFlip, RandomRotation, RandomTranslation, RandomCrop, RandomBrightness\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImg(filenames, labels, size, resize, rescale):\n",
    "    images = []\n",
    "    for i, name in (nameMsg := tqdm(enumerate(filenames))):\n",
    "        nameMsg.set_description(\n",
    "            f\"{((i+1) / labels.shape[0]) * 100:.2f}% loaded\")\n",
    "        nameMsg.set_postfix_str(name)\n",
    "        try:\n",
    "            img = tf.keras.preprocessing.image.load_img(name)\n",
    "        except:\n",
    "            labels = np.delete(labels, i)\n",
    "            continue\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        if resize:\n",
    "            img = tf.image.resize(img, (size, size))\n",
    "\n",
    "        if rescale == 1:\n",
    "            img = img / 255\n",
    "        elif rescale == 2:\n",
    "            img = (img / 127.5) - 1\n",
    "        else:\n",
    "            img = tf.cast(img, tf.uint8)\n",
    "\n",
    "        images.append(img)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def parseData(filename, delimiter=',', size=False, resize=False, rescale=True, return_format='dataset'):\n",
    "    if resize:\n",
    "        if not size:\n",
    "            raise Exception('Size must be specified when resize is true.')\n",
    "\n",
    "    if return_format.lower() not in ['dataset', 'labels', 'images']:\n",
    "        raise Exception(\"Return format unspecified.\")\n",
    "\n",
    "    images = []\n",
    "    train_df = pd.read_csv(str(filename)+\"_classes.csv\", delimiter=delimiter)\n",
    "    img_dir = np.array(train_df.pop('filename'))\n",
    "    img_dir = np.ndarray.flatten(img_dir)\n",
    "\n",
    "    for row, img_path in enumerate(img_dir):\n",
    "        img_dir[row] = os.path.join(filename, img_path)\n",
    "\n",
    "    labels = np.array(train_df.idxmax(axis=1).str.strip().astype(\n",
    "        'category').cat.codes).reshape(-1, 1)\n",
    "\n",
    "    images, labels = loadImg(img_dir, labels, size, resize, rescale)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if return_format == 'dataset':\n",
    "        return dataset\n",
    "    elif return_format == 'images':\n",
    "        return images\n",
    "    elif return_format == 'labels':\n",
    "        return labels\n",
    "    else:\n",
    "        raise Exception(\"Return format unspecified.\")\n",
    "\n",
    "\n",
    "def confusionMatrix(epoch, logs):\n",
    "    yhat = model.predict(test_images)\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    cm = confusion_matrix(test_labels, yhat)\n",
    "\n",
    "    plt.matshow(cm)\n",
    "    for (x, y), value in np.ndenumerate(data):\n",
    "        plt.text(x, y, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
    "    plt.title(\n",
    "        f\"Confusion Matrix on epoch {epoch}\\nVal accuracy: {logs.get('val_accuracy')}\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f\"./CM/CM Epoch {epoch}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {0: 'bacterial_blight', 1: 'Blast',\n",
    "                2: 'Brownspot', 3: 'leaf_scald', 4: 'leaf_burn', 5: 'tungro'}\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_dataset = parseData(\"./dataset/train/\", size=img_size,\n",
    "                              resize=True, rescale=1)\n",
    "    valid_dataset = parseData(\"./dataset/valid/\", size=img_size,\n",
    "                              resize=True, rescale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    test_labels = parseData(\"./dataset/test/\", size=img_size,\n",
    "                            resize=True, rescale=1, return_format='labels')\n",
    "    test_images_data = parseData(\"./dataset/test/\", size=img_size,\n",
    "                                 resize=True, rescale=1, return_format='images')\n",
    "    test_images = tf.data.Dataset.from_tensor_slices(test_images_data)\n",
    "    test_images = test_images.batch(32).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_dataset.shuffle(512).cache().batch(32).prefetch(AUTOTUNE)\n",
    "valid = valid_dataset.cache().batch(32).prefetch(AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buat Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "#     include_top=False, input_shape=(img_size, img_size, 3), pooling='max')\n",
    "# base_model.trainable = False\n",
    "\n",
    "base_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Input((img_size, img_size, 3)),\n",
    "    # RandomFlip(),\n",
    "    # RandomRotation(factor=0.2),\n",
    "    # RandomZoom(height_factor=(-0.2, 0.2)),\n",
    "    base_model,\n",
    "    # Dense(512, 'selu'),\n",
    "    # Dropout(0.2),\n",
    "    # Dense(32, 'selu'),\n",
    "    Dense(len(disease_dict.keys()), 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    optimizer=Adam(0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "bestCB = ModelCheckpoint(filepath='./checkpoint/best/', monitor='val_accuracy',\n",
    "                         mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "cmCB = LambdaCallback(on_epoch_end=confusionMatrix)\n",
    "\n",
    "model.build([None, img_size, img_size, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=valid,\n",
    "        epochs=10,\n",
    "        callbacks=[bestCB, cmCB]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./checkpoint/latest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = history.epoch\n",
    "\n",
    "plt.plot(epochs, acc, label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model's Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label='Train Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Model's Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluasi Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iterasi terakhir\n",
    "model = tf.keras.models.load_model(\"./checkpoint/latest/\")\n",
    "\n",
    "# Load terbaik\n",
    "# model = tf.keras.models.load_model(\"./checkpoint/best/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    test_dataset = parseData(\"./dataset/test/\", size=img_size,\n",
    "                             resize=True, rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_dataset.shuffle(128).cache().batch(32).prefetch(AUTOTUNE)\n",
    "# testBatch = test.batch(1)\n",
    "# model.evaluate(testBatch)\n",
    "\n",
    "for image, label in test:\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    yhat = model.predict(image)\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    result = \"benar\" if yhat == label else \"salah\"\n",
    "    print(f\"Label asli: {label}\\nPrediksi: {yhat} {result}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
